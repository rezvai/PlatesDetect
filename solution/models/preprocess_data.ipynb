{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Необходимые модули: \n",
    "conda create -n `EnvName` python=3.9-3.11\n",
    "\n",
    "conda activate `EnvName`\n",
    "\n",
    "conda install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все папки успешно созданы!\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "source_dir = 'data'\n",
    "source_types = ['ctype1', 'ctype2', 'ctype3', 'ctype4', 'all_ctypes']\n",
    "datasets_dir = 'datasets'\n",
    "datasets = ['ctype1_data', 'ctype2_data', 'ctype3_data', 'ctype4_data', 'all_ctypes_data']\n",
    "dataset_dirs = ['train\\\\images', 'train\\\\labels', 'val\\\\images', 'val\\\\labels', 'test\\\\images', 'test\\\\labels']\n",
    "\n",
    "for dir in source_types:\n",
    "    path = os.path.join(source_dir, dir, 'images')\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "for dir in dataset_dirs:\n",
    "    for dataset in datasets:\n",
    "        path = os.path.join(datasets_dir, dataset, dir)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "models = ['model_ctype1', 'model_ctype2', 'model_ctype3', 'model_ctype4', 'model_all_ctypes']\n",
    "for model in models:\n",
    "    path = os.path.join(model)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "print('Все папки успешно созданы!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все реальные фото находятся в папках data: TestTask\\solution\\models\\data\\...\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "data_ctypes = ['al-ctype-1', 'al-ctype-2', 'al-ctype-3', 'al-ctype-4']\n",
    "\n",
    "for i in range(len(data_ctypes)):\n",
    "    for  dir in os.listdir(os.path.join('..', data_ctypes[i])):\n",
    "        path = os.path.join('..', data_ctypes[i], dir)\n",
    "        for file in os.listdir(os.path.join(path)):\n",
    "            if file.startswith('real_'):\n",
    "                shutil.copy(os.path.join(path, file), os.path.join('..\\\\models\\data', source_types[i], 'images')) \n",
    "                shutil.copy(os.path.join(path, file), os.path.join('..\\\\models\\data\\\\all_ctypes\\\\images')) \n",
    "                \n",
    "\n",
    "print('Все реальные фото находятся в папках data: TestTask\\solution\\models\\data\\...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После создания всех нужных дирректорий, была выполненна работа по разметке данных, с помощью приложения:\n",
    "* https://github.com/cvat-ai/cvat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ctype1', 'ctype2', 'ctype3', 'ctype4', 'all_ctypes']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join('data')).remove('all_ctypes')\n",
    "\n",
    "os.listdir(os.path.join('data'))[1:] + os.listdir(os.path.join('data'))[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctype1: \n",
      "train_images: 891\n",
      "train_labels: 891\n",
      "val_images: 49\n",
      "val_labels: 49\n",
      "test_images: 50\n",
      "test_labels: 50\n",
      "_________________________________________\n",
      "ctype2: \n",
      "train_images: 54\n",
      "train_labels: 54\n",
      "val_images: 3\n",
      "val_labels: 3\n",
      "test_images: 3\n",
      "test_labels: 3\n",
      "_________________________________________\n",
      "ctype3: \n",
      "train_images: 221\n",
      "train_labels: 221\n",
      "val_images: 19\n",
      "val_labels: 19\n",
      "test_images: 20\n",
      "test_labels: 20\n",
      "_________________________________________\n",
      "ctype4: \n",
      "train_images: 594\n",
      "train_labels: 594\n",
      "val_images: 33\n",
      "val_labels: 33\n",
      "test_images: 33\n",
      "test_labels: 33\n",
      "_________________________________________\n",
      "all_ctypes: \n",
      "train_images: 1773\n",
      "train_labels: 1773\n",
      "val_images: 98\n",
      "val_labels: 98\n",
      "test_images: 99\n",
      "test_labels: 99\n",
      "_________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "images = [[file for file in os.listdir(os.path.join('data', dir, 'obj_train_data')) if file.endswith('.jpg')] for dir in os.listdir(os.path.join('data'))[1:] + os.listdir(os.path.join('data'))[:1]]\n",
    "labels = [[file for file in os.listdir(os.path.join('data', dir, 'obj_train_data')) if file.endswith('.txt')] for dir in os.listdir(os.path.join('data'))[1:] + os.listdir(os.path.join('data'))[:1]]\n",
    "\n",
    "val_sizes = [0.1, 0.1, 0.15, 0.1, 0.1]\n",
    "\n",
    "keys_data = ['train_images', 'test_images', 'val_images', 'val_labels', 'test_images', 'test_labels']\n",
    "data = {i: {j: None for j in keys_data} for i in source_types}\n",
    "\n",
    "for i in range(len(images)):\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(images[i], labels[i], test_size=val_sizes[i], random_state=42)\n",
    "    val_images, test_images, val_labels, test_labels = train_test_split(val_images, val_labels, test_size=0.5, random_state=42)\n",
    "    data[source_types[i]]['train_images'] = train_images\n",
    "    data[source_types[i]]['train_labels'] = train_labels\n",
    "    data[source_types[i]]['val_images'] = val_images\n",
    "    data[source_types[i]]['val_labels'] = val_labels\n",
    "    data[source_types[i]]['test_images'] = test_images\n",
    "    data[source_types[i]]['test_labels'] = test_labels\n",
    "    print(f\"{source_types[i]}: \\ntrain_images: {len(train_images)}\\ntrain_labels: {len(train_labels)}\\nval_images: {len(val_images)}\\nval_labels: {len(val_labels)}\\ntest_images: {len(test_images)}\\ntest_labels: {len(test_labels)}\")\n",
    "    print('_________________________________________')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все изображения и разметка успешно перенесенены в в датасет и структурированны!\n"
     ]
    }
   ],
   "source": [
    "for ctype in source_types:\n",
    "    for key in data[ctype].keys():\n",
    "        for file in data[ctype][key]:\n",
    "            shutil.copy(os.path.join('data', ctype,'obj_train_data', file), os.path.join('datasets', f'{ctype}_data', key.replace('_', '\\\\')))\n",
    "\n",
    "print('Все изображения и разметка успешно перенесенены в в датасет и структурированны!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные успешно подготовленны и структурированны для дальнейшего обучения моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testtask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
